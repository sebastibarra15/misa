{
  "cells": [
    {
      "cell_type": "code",
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-11-28T15:24:40.355999Z",
          "start_time": "2024-11-28T15:24:40.345729Z"
        },
        "id": "initial_id"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models # Import the layers and models modules from keras\n",
        "from scipy.ndimage import zoom\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Organize Data\n",
        "# Directory containing the files\n",
        "base_dir = \"/content\"\n",
        "\n",
        "# List all files in the directory\n",
        "all_files = sorted(os.listdir(base_dir))\n",
        "\n",
        "# Create dictionaries for images and labels\n",
        "images = {}\n",
        "labels = {}\n",
        "\n",
        "for file_name in all_files:\n",
        "    if file_name.endswith(\".nii.gz\"):  # Only consider .nii.gz files\n",
        "        if \"_seg\" in file_name:  # Label files\n",
        "            key = file_name.replace(\"IBSR_\", \"\").replace(\"_seg.nii.gz\", \"\")\n",
        "            labels[key] = os.path.join(base_dir, file_name)\n",
        "        else:  # Image files\n",
        "            key = file_name.replace(\"IBSR_\", \"\").replace(\".nii.gz\", \"\")\n",
        "            images[key] = os.path.join(base_dir, file_name)\n",
        "\n",
        "# Debugging: Display the dictionaries\n",
        "print(\"Images Dictionary:\", images)\n",
        "print(\"Labels Dictionary:\", labels)\n",
        "\n",
        "# Training and Validation Data\n",
        "training_keys = ['01', '03', '04', '05', '06', '07', '08', '09', '18']\n",
        "validation_keys = ['11', '12', '13', '14', '17']\n",
        "\n",
        "training_images = {k: images[k] for k in training_keys}\n",
        "training_labels = {k: labels[k] for k in training_keys}\n",
        "validation_images = {k: images[k] for k in validation_keys}\n",
        "validation_labels = {k: labels[k] for k in validation_keys}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6h3p0DJ98xD",
        "outputId": "9b6619f8-bf5c-4272-dfd2-813027806cec"
      },
      "id": "N6h3p0DJ98xD",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images Dictionary: {'01': '/content/IBSR_01.nii.gz', '03': '/content/IBSR_03.nii.gz', '04': '/content/IBSR_04.nii.gz', '05': '/content/IBSR_05.nii.gz', '06': '/content/IBSR_06.nii.gz', '07': '/content/IBSR_07.nii.gz', '08': '/content/IBSR_08.nii.gz', '09': '/content/IBSR_09.nii.gz', '11': '/content/IBSR_11.nii.gz', '12': '/content/IBSR_12.nii.gz', '13': '/content/IBSR_13.nii.gz', '14': '/content/IBSR_14.nii.gz', '16': '/content/IBSR_16.nii.gz', '17': '/content/IBSR_17.nii.gz', '18': '/content/IBSR_18.nii.gz'}\n",
            "Labels Dictionary: {'01': '/content/IBSR_01_seg.nii.gz', '03': '/content/IBSR_03_seg.nii.gz', '04': '/content/IBSR_04_seg.nii.gz', '05': '/content/IBSR_05_seg.nii.gz', '06': '/content/IBSR_06_seg.nii.gz', '07': '/content/IBSR_07_seg.nii.gz', '08': '/content/IBSR_08_seg.nii.gz', '09': '/content/IBSR_09_seg.nii.gz', '11': '/content/IBSR_11_seg.nii.gz', '12': '/content/IBSR_12_seg.nii.gz', '13': '/content/IBSR_13_seg.nii.gz', '14': '/content/IBSR_14_seg.nii.gz', '16': '/content/IBSR_16_seg.nii.gz', '17': '/content/IBSR_17_seg.nii.gz', '18': '/content/IBSR_18_seg.nii.gz'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocess Data\n",
        "def load_nifti(file_path):\n",
        "    \"\"\"Load a NIfTI file.\"\"\"\n",
        "    img = nib.load(file_path)\n",
        "    return img.get_fdata()\n",
        "\n",
        "def normalize_image(image):\n",
        "    \"\"\"\n",
        "    Normalize the image intensity values to the range [0, 1].\n",
        "    Handles images with uniform intensity values gracefully.\n",
        "    \"\"\"\n",
        "    min_val = np.min(image)\n",
        "    max_val = np.max(image)\n",
        "    if max_val - min_val == 0:  # Avoid division by zero\n",
        "        return np.zeros_like(image)\n",
        "    return (image - min_val) / (max_val - min_val)\n",
        "\n",
        "\n",
        "def resize_image(image, target_shape):\n",
        "    \"\"\"\n",
        "    Resize an image to the target shape using interpolation.\n",
        "    Handles images with an additional channel dimension.\n",
        "    \"\"\"\n",
        "    if len(image.shape) == len(target_shape) + 1:  # If image has extra channel dimension\n",
        "        # Resize only the spatial dimensions\n",
        "        spatial_shape = image.shape[:-1]\n",
        "        zoom_factors = [t / s for t, s in zip(target_shape, spatial_shape)]\n",
        "        resized_image = zoom(image[..., 0], zoom_factors, order=1)  # Remove channel, resize, and re-add it\n",
        "        return resized_image[..., np.newaxis]  # Add channel dimension back\n",
        "    elif len(image.shape) == len(target_shape):  # If image matches target rank\n",
        "        zoom_factors = [t / s for t, s in zip(target_shape, image.shape)]\n",
        "        resized_image = zoom(image, zoom_factors, order=1)\n",
        "        return resized_image\n",
        "    else:\n",
        "        raise ValueError(f\"Target shape {target_shape} and input shape {image.shape} must match in rank.\")\n",
        "\n",
        "def preprocess_data(images_dict, labels_dict, target_shape, n_classes):\n",
        "    \"\"\"\n",
        "    Preprocess the images and labels: normalize, resize, and encode.\n",
        "    \"\"\"\n",
        "    images_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    for key in sorted(images_dict.keys()):\n",
        "        # Load and preprocess images\n",
        "        image = load_nifti(images_dict[key])\n",
        "        print(f\"Original image shape {key}: {image.shape}\")\n",
        "        image = normalize_image(image)\n",
        "        image_resized = resize_image(image, target_shape)\n",
        "        print(f\"Resized image shape {key}: {image_resized.shape}\")\n",
        "        images_list.append(image_resized)\n",
        "\n",
        "        # Load and preprocess labels (if available)\n",
        "        if key in labels_dict:\n",
        "            label = load_nifti(labels_dict[key])\n",
        "            print(f\"Original label shape {key}: {label.shape}\")\n",
        "            label_resized = resize_image(label, target_shape)\n",
        "            print(f\"Resized label shape {key}: {label_resized.shape}\")\n",
        "            labels_list.append(label_resized)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    images_array = np.array(images_list)\n",
        "    images_array = images_array[..., np.newaxis]  # Ensure channel dimension (5D)\n",
        "    print(f\"Images array shape: {images_array.shape}\")\n",
        "\n",
        "    if labels_list:  # Check if labels_list is not empty\n",
        "        labels_array = np.array(labels_list, dtype=np.int32)\n",
        "        labels_array = to_categorical(labels_array, num_classes=n_classes)  # One-hot encode labels\n",
        "        print(f\"Labels array shape: {labels_array.shape}\")\n",
        "    else:\n",
        "        labels_array = None\n",
        "        print(\"Warning: No labels found during preprocessing.\")\n",
        "\n",
        "    return images_array, labels_array\n",
        "\n",
        "# Target shape for images\n",
        "target_shape = (256, 128, 256)\n",
        "n_classes = 4\n",
        "\n",
        "# Preprocess training and validation data\n",
        "training_images_array, training_labels_array = preprocess_data(\n",
        "    training_images, training_labels, target_shape, n_classes\n",
        ")\n",
        "validation_images_array, validation_labels_array = preprocess_data(\n",
        "    validation_images, validation_labels, target_shape, n_classes\n",
        ")\n",
        "\n",
        "print(f\"Training Images Shape: {training_images_array.shape}\")\n",
        "print(f\"Training Labels Shape: {training_labels_array.shape}\")\n",
        "print(f\"Validation Images Shape: {validation_images_array.shape}\")\n",
        "print(f\"Validation Labels Shape: {validation_labels_array.shape}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jWNp0e3-BMl",
        "outputId": "24c35b55-193f-423c-a284-d447c0c18328"
      },
      "id": "5jWNp0e3-BMl",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original image shape 01: (256, 128, 256, 1)\n",
            "Resized image shape 01: (256, 128, 256, 1)\n",
            "Original label shape 01: (256, 128, 256, 1)\n",
            "Resized label shape 01: (256, 128, 256, 1)\n",
            "Original image shape 03: (256, 128, 256, 1)\n",
            "Resized image shape 03: (256, 128, 256, 1)\n",
            "Original label shape 03: (256, 128, 256, 1)\n",
            "Resized label shape 03: (256, 128, 256, 1)\n",
            "Original image shape 04: (256, 128, 256, 1)\n",
            "Resized image shape 04: (256, 128, 256, 1)\n",
            "Original label shape 04: (256, 128, 256, 1)\n",
            "Resized label shape 04: (256, 128, 256, 1)\n",
            "Original image shape 05: (256, 128, 256, 1)\n",
            "Resized image shape 05: (256, 128, 256, 1)\n",
            "Original label shape 05: (256, 128, 256, 1)\n",
            "Resized label shape 05: (256, 128, 256, 1)\n",
            "Original image shape 06: (256, 128, 256, 1)\n",
            "Resized image shape 06: (256, 128, 256, 1)\n",
            "Original label shape 06: (256, 128, 256, 1)\n",
            "Resized label shape 06: (256, 128, 256, 1)\n",
            "Original image shape 07: (256, 128, 256, 1)\n",
            "Resized image shape 07: (256, 128, 256, 1)\n",
            "Original label shape 07: (256, 128, 256, 1)\n",
            "Resized label shape 07: (256, 128, 256, 1)\n",
            "Original image shape 08: (256, 128, 256, 1)\n",
            "Resized image shape 08: (256, 128, 256, 1)\n",
            "Original label shape 08: (256, 128, 256, 1)\n",
            "Resized label shape 08: (256, 128, 256, 1)\n",
            "Original image shape 09: (256, 128, 256, 1)\n",
            "Resized image shape 09: (256, 128, 256, 1)\n",
            "Original label shape 09: (256, 128, 256, 1)\n",
            "Resized label shape 09: (256, 128, 256, 1)\n",
            "Original image shape 18: (256, 128, 256, 1)\n",
            "Resized image shape 18: (256, 128, 256, 1)\n",
            "Original label shape 18: (256, 128, 256, 1)\n",
            "Resized label shape 18: (256, 128, 256, 1)\n",
            "Images array shape: (9, 256, 128, 256, 1, 1)\n",
            "Labels array shape: (9, 256, 128, 256, 4)\n",
            "Original image shape 11: (256, 128, 256, 1)\n",
            "Resized image shape 11: (256, 128, 256, 1)\n",
            "Original label shape 11: (256, 128, 256, 1)\n",
            "Resized label shape 11: (256, 128, 256, 1)\n",
            "Original image shape 12: (256, 128, 256, 1)\n",
            "Resized image shape 12: (256, 128, 256, 1)\n",
            "Original label shape 12: (256, 128, 256, 1)\n",
            "Resized label shape 12: (256, 128, 256, 1)\n",
            "Original image shape 13: (256, 128, 256, 1)\n",
            "Resized image shape 13: (256, 128, 256, 1)\n",
            "Original label shape 13: (256, 128, 256, 1)\n",
            "Resized label shape 13: (256, 128, 256, 1)\n",
            "Original image shape 14: (256, 128, 256, 1)\n",
            "Resized image shape 14: (256, 128, 256, 1)\n",
            "Original label shape 14: (256, 128, 256, 1)\n",
            "Resized label shape 14: (256, 128, 256, 1)\n",
            "Original image shape 17: (256, 128, 256, 1)\n",
            "Resized image shape 17: (256, 128, 256, 1)\n",
            "Original label shape 17: (256, 128, 256, 1)\n",
            "Resized label shape 17: (256, 128, 256, 1)\n",
            "Images array shape: (5, 256, 128, 256, 1, 1)\n",
            "Labels array shape: (5, 256, 128, 256, 4)\n",
            "Training Images Shape: (9, 256, 128, 256, 1, 1)\n",
            "Training Labels Shape: (9, 256, 128, 256, 4)\n",
            "Validation Images Shape: (5, 256, 128, 256, 1, 1)\n",
            "Validation Labels Shape: (5, 256, 128, 256, 4)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a612a5ad8fb8043",
        "outputId": "fa361b32-5f2b-4077-d530-d8af6ed8ff77"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vol_patches shape: (73728, 32, 32, 1)\n",
            "seg_patches shape: (294912, 32, 32)\n",
            "useful_patches count: 73728\n",
            "vol_patches shape: (40960, 32, 32, 1)\n",
            "seg_patches shape: (163840, 32, 32)\n",
            "useful_patches count: 40960\n",
            "Training Patches Shape: (73728, 32, 32, 1)\n",
            "Validation Patches Shape: (40960, 32, 32, 1)\n"
          ]
        }
      ],
      "execution_count": 5,
      "source": [
        "def extract_patches(images, labels, patch_size, stride, threshold, num_classes):\n",
        "    \"\"\"\n",
        "    Extract useful patches from 4D or 5D images and labels.\n",
        "    \"\"\"\n",
        "    # Reshape images and labels if they have extra dimensions\n",
        "    if images.ndim == 6:\n",
        "        batch_size, depth, height, width, channels, _ = images.shape\n",
        "        images = images.reshape(batch_size * depth, height, width, channels)\n",
        "    elif images.ndim == 5:\n",
        "        batch_size, height, width, depth, channels = images.shape\n",
        "        images = images.reshape(batch_size * depth, height, width, channels)\n",
        "\n",
        "    if labels.ndim == 6:\n",
        "        batch_size, depth, height, width, channels, _ = labels.shape\n",
        "        labels = labels.reshape(batch_size * depth, height, width, channels)\n",
        "    elif labels.ndim == 5:\n",
        "        batch_size, height, width, depth, channels = labels.shape\n",
        "        labels = labels.reshape(batch_size * depth, height, width, channels)\n",
        "\n",
        "    # Transpose labels if needed\n",
        "    if images.shape[1:3] != labels.shape[1:3]:  # Compare height and width\n",
        "        labels = np.transpose(labels, axes=(0, 2, 1, 3))  # Swap height and width\n",
        "\n",
        "    # Check input dimensions\n",
        "    assert images.shape[:3] == labels.shape[:3], (\n",
        "        f\"Images and labels must have the same spatial dimensions. \"\n",
        "        f\"Images shape: {images.shape}, Labels shape: {labels.shape}\"\n",
        "    )\n",
        "\n",
        "    # Extract patches\n",
        "    vol_patches = tf.image.extract_patches(\n",
        "        images=images,\n",
        "        sizes=[1, *patch_size, 1],\n",
        "        strides=[1, *stride, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding=\"SAME\"\n",
        "    ).numpy()\n",
        "\n",
        "    seg_patches = tf.image.extract_patches(\n",
        "        images=labels,\n",
        "        sizes=[1, *patch_size, 1],\n",
        "        strides=[1, *stride, 1],\n",
        "        rates=[1, 1, 1, 1],\n",
        "        padding=\"SAME\"\n",
        "    ).numpy()\n",
        "\n",
        "    # Reshape patches\n",
        "    vol_patches = vol_patches.reshape([-1, *patch_size, 1])\n",
        "    seg_patches = seg_patches.reshape([-1, *patch_size])\n",
        "\n",
        "    # Adjust the foreground mask to match vol_patches\n",
        "    foreground_mask = seg_patches.sum(axis=(1, 2)) > 0  # Only keep patches with non-zero labels\n",
        "    useful_patches = np.arange(len(vol_patches))[foreground_mask[:len(vol_patches)]]  # Adjust length\n",
        "\n",
        "    # Debug shapes\n",
        "    print(f\"vol_patches shape: {vol_patches.shape}\")\n",
        "    print(f\"seg_patches shape: {seg_patches.shape}\")\n",
        "    print(f\"useful_patches count: {len(useful_patches)}\")\n",
        "\n",
        "    # Apply the filtering mask\n",
        "    vol_patches = vol_patches[useful_patches]\n",
        "    seg_patches = seg_patches[useful_patches]\n",
        "\n",
        "    # Convert labels to one-hot encoding\n",
        "    seg_patches = tf.keras.utils.to_categorical(seg_patches, num_classes=num_classes)\n",
        "\n",
        "    return vol_patches, seg_patches\n",
        "\n",
        "\n",
        "# Patch parameters\n",
        "patch_size = (16, 16)\n",
        "stride = (16, 16)\n",
        "threshold = 0.5\n",
        "\n",
        "# Extract patches\n",
        "x_train, y_train = extract_patches(\n",
        "    training_images_array,\n",
        "    training_labels_array,\n",
        "    patch_size,\n",
        "    stride,\n",
        "    threshold,\n",
        "    n_classes\n",
        ")\n",
        "x_val, y_val = extract_patches(\n",
        "    validation_images_array,\n",
        "    validation_labels_array,\n",
        "    patch_size,\n",
        "    stride,\n",
        "    threshold,\n",
        "    n_classes\n",
        ")\n",
        "\n",
        "print(f\"Training Patches Shape: {x_train.shape}\")\n",
        "print(f\"Validation Patches Shape: {x_val.shape}\")\n"
      ],
      "id": "1a612a5ad8fb8043"
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Build the SegNet Model\n",
        "def get_segnet(img_size, n_classes, n_input_channels):\n",
        "    inputs = tf.keras.Input(shape=img_size + (n_input_channels,))\n",
        "\n",
        "    # Encoding Path\n",
        "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
        "\n",
        "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
        "\n",
        "    # Decoding Path\n",
        "    up1 = layers.UpSampling2D((2, 2))(pool3)\n",
        "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up1)\n",
        "\n",
        "    up2 = layers.UpSampling2D((2, 2))(conv4)\n",
        "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up2)\n",
        "\n",
        "    up3 = layers.UpSampling2D((2, 2))(conv5)\n",
        "    conv6 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(up3)\n",
        "\n",
        "    outputs = layers.Conv2D(n_classes, (1, 1), activation='softmax')(conv6)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "segnet = get_segnet(img_size=(32, 32), n_classes=n_classes, n_input_channels=1)\n",
        "segnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 5: Train the Model\n",
        "batch_size = 32\n",
        "epochs = 20\n",
        "\n",
        "history = segnet.fit(\n",
        "    x_train, y_train,\n",
        "    validation_data=(x_val, y_val),\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Step 6: Visualize Training Results\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tu23NoS9_fta"
      },
      "id": "Tu23NoS9_fta",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}